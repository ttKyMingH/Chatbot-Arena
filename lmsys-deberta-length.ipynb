{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":66631,"databundleVersionId":8346466,"sourceType":"competition"},{"sourceId":8820093,"sourceType":"datasetVersion","datasetId":5306138},{"sourceId":8826860,"sourceType":"datasetVersion","datasetId":5310688},{"sourceId":8826894,"sourceType":"datasetVersion","datasetId":5310716},{"sourceId":6063,"sourceType":"modelInstanceVersion","modelInstanceId":4684}],"dockerImageVersionId":30733,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries ","metadata":{}},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # or \"jax\" or \"torch\"\nimport re\n\nimport keras_nlp\nimport keras\nimport tensorflow as tf\n\nimport numpy as np \nimport pandas as pd\nfrom tqdm import tqdm\nimport json\n\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport plotly.express as px","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2024-07-01T05:42:43.829095Z","iopub.execute_input":"2024-07-01T05:42:43.829460Z","iopub.status.idle":"2024-07-01T05:42:43.836148Z","shell.execute_reply.started":"2024-07-01T05:42:43.829433Z","shell.execute_reply":"2024-07-01T05:42:43.835174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Num GPUs Available","metadata":{}},{"cell_type":"code","source":"print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\nstrategy = tf.distribute.MirroredStrategy()\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:42:43.838432Z","iopub.execute_input":"2024-07-01T05:42:43.838706Z","iopub.status.idle":"2024-07-01T05:42:43.852598Z","shell.execute_reply.started":"2024-07-01T05:42:43.838682Z","shell.execute_reply":"2024-07-01T05:42:43.851585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"class CFG:\n    seed = 42  # Random seed\n    preset = \"deberta_v3_extra_small_en\"\n    sequence_length = 512\n    epochs = 6\n    batch_size = 16\n    scheduler = 'cosine'  # Learning rate scheduler\n    label2name = {0: 'winner_model_a', 1: 'winner_model_b', 2: 'winner_tie'}\n    name2label = {v:k for k, v in label2name.items()}\n    class_labels = list(label2name.keys())\n    class_names = list(label2name.values())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-01T05:42:43.854194Z","iopub.execute_input":"2024-07-01T05:42:43.854542Z","iopub.status.idle":"2024-07-01T05:42:43.862088Z","shell.execute_reply.started":"2024-07-01T05:42:43.854510Z","shell.execute_reply":"2024-07-01T05:42:43.860936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reproducibility \nSets value for random seed to produce similar result in each run.","metadata":{}},{"cell_type":"code","source":"keras.utils.set_random_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:42:43.863313Z","iopub.execute_input":"2024-07-01T05:42:43.863625Z","iopub.status.idle":"2024-07-01T05:42:43.875207Z","shell.execute_reply.started":"2024-07-01T05:42:43.863597Z","shell.execute_reply":"2024-07-01T05:42:43.874296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Mixed Precision\n\nIn this notebook, we will use mixed precision instead of float32 precision for training and inference to reduce GPU memory usage. This will ultimately allow us to use larger batch sizes, thus reducing our training and inference time.","metadata":{}},{"cell_type":"code","source":"keras.mixed_precision.set_global_policy(\"mixed_float16\")","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:42:43.877720Z","iopub.execute_input":"2024-07-01T05:42:43.878053Z","iopub.status.idle":"2024-07-01T05:42:43.884289Z","shell.execute_reply.started":"2024-07-01T05:42:43.878025Z","shell.execute_reply":"2024-07-01T05:42:43.883335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Path ","metadata":{}},{"cell_type":"code","source":"BASE_PATH = '/kaggle/input/lmsys-chatbot-arena'","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:42:43.885662Z","iopub.execute_input":"2024-07-01T05:42:43.886391Z","iopub.status.idle":"2024-07-01T05:42:43.894550Z","shell.execute_reply.started":"2024-07-01T05:42:43.886354Z","shell.execute_reply":"2024-07-01T05:42:43.893533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Meta Data \n## Files\n\n### `train.csv`\n- `id`: Unique identifier for each row.\n- `model_[a/b]`: Model identity, present in train.csv but not in test.csv.\n- `prompt`: Input prompt given to both models.\n- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n- `winner_model_[a/b/tie]`: Binary columns indicating the judge's selection (ground truth target).\n\n### `test.csv`\n- `id`: Unique identifier for each row.\n- `prompt`: Input prompt given to both models.\n- `response_[a/b]`: Model_[a/b]'s response to the prompt.\n\n> Note that each interaction may have multiple prompts and responses, but this notebook will use only **one prompt per interaction**. You can choose to use all prompts and responses. Additionally, prompts and responses in the dataframe are provided as string-formatted lists, so they need to be converted to literal lists using `eval()`.\n","metadata":{}},{"cell_type":"code","source":"# Load Train Data\ndf = pd.read_csv(f'{BASE_PATH}/train.csv') \nultrachat_df = pd.read_csv('/kaggle/input/ultrachat-train/ultrachat_s42_a0.5.csv')\ndf = pd.concat([df, ultrachat_df], axis=0)\nlmsys_33k_deduplicated = pd.read_csv('/kaggle/input/lmsys-33k-deduplicated/lmsys-33k-deduplicated.csv')\ndf = pd.concat([df, lmsys_33k_deduplicated], axis=0)\n# ultrafeedback_lmsysformat = pd.read_parquet('/kaggle/input/ultrafeedback-lmsysformat/ultrafeedback_lmsysformat.parquet', engine='pyarrow')\n# ultrafeedback_lmsysformat['prompt'] = ultrafeedback_lmsysformat['prompt'].apply(lambda x: f'[\"{x}\"]')\n# df = pd.concat([df, ultrafeedback_lmsysformat], axis=0)\n\n# Load Test Data\ntest_df = pd.read_csv(f'{BASE_PATH}/test.csv')\n\n# display(ultrafeedback_lmsysformat.head())\ndisplay(df.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:42:43.895860Z","iopub.execute_input":"2024-07-01T05:42:43.896494Z","iopub.status.idle":"2024-07-01T05:42:47.570972Z","shell.execute_reply.started":"2024-07-01T05:42:43.896469Z","shell.execute_reply":"2024-07-01T05:42:47.570076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(\"id\", axis=1)\ndf = df.drop_duplicates(keep=\"first\", ignore_index=True)\n\nfor col in [\"prompt\"]:\n    df[col] = df[col].apply(lambda x: eval(x))\n    test_df[col] = test_df[col].apply(lambda x: eval(x))\nfor col in [\"response_a\", \"response_b\"]:\n    df[col] = df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))\n    test_df[col] = test_df[col].apply(lambda x: eval(x.replace(\"null\", \"None\")))\n    \n# Sample data\n# df = df.sample(frac=0.01)\n\n# Label conversion\ndf[\"class_name\"] = df[[\"winner_model_a\", \"winner_model_b\" , \"winner_tie\"]].idxmax(axis=1)\ndf[\"class_label\"] = df.class_name.map(CFG.name2label)\n\n# Show Sample\ndisplay(df.head())\n# Show Sample\ndisplay(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:42:47.572197Z","iopub.execute_input":"2024-07-01T05:42:47.572495Z","iopub.status.idle":"2024-07-01T05:42:56.981935Z","shell.execute_reply.started":"2024-07-01T05:42:47.572468Z","shell.execute_reply":"2024-07-01T05:42:56.981115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Contextualize Response with Prompt\n\nIn our approach, we will contextualize each response with the prompt instead of using a single prompt for all responses. This means that for each response, we will provide the model with the same set of prompts combined with their respective response (e.g., `(P + R_A)`, `(P + R_B)`, etc.). This approach is similar to the multiple-choice question task in NLP.\n\n> Note that some prompts and responses may not be encoded with `utf-8`, resulting in errors when creating the dataloader. In such cases, we will replace them with an empty string.\n","metadata":{}},{"cell_type":"code","source":"def make_pairs(row):\n    row['options'] = []\n    row[\"encode_fail\"] = False\n\n    try:\n        # 确保所有需要的键都存在于row字典中\n        prompts = row['prompt']\n        responses_a = row['response_a']\n        responses_b = row['response_b']\n        \n        # 检查列表长度是否匹配\n        if not (len(prompts) == len(responses_a) == len(responses_b)):\n            raise ValueError(\"The lists 'prompt', 'response_a', and 'response_b' must be of the same length.\")\n            \n        response_a_str = ''\n        response_b_str = ''\n        \n        for idx in range(len(prompts)):\n            response_a_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_a[idx]}\"\n            response_b_str += f\"Prompt: {prompts[idx]}\\n\\nResponse: {responses_b[idx]}\"\n        \n        # 文本清洗，例如去除无法识别的Unicode字符或替换它们\n        clean_response_a_str = \"\".join(filter(lambda x: ord(x) < 128, response_a_str))\n        clean_response_a_str = \"\".join(filter(lambda x: ord(x) < 128, response_b_str))\n        \n        row['options'].append(clean_response_a_str)\n        row['options'].append(clean_response_a_str)\n        \n    except KeyError as e:\n        print(f\"Missing key in row: {e}\")\n        row[\"encode_fail\"] = True\n    except ValueError as e:\n        print(e)\n        row[\"encode_fail\"] = True\n    except Exception as e:\n        # 捕获其他所有异常\n        print(f\"An unexpected error occurred: {e}\")\n        row[\"encode_fail\"] = True\n\n    return row","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:42:56.990688Z","iopub.execute_input":"2024-07-01T05:42:56.990990Z","iopub.status.idle":"2024-07-01T05:42:57.002862Z","shell.execute_reply.started":"2024-07-01T05:42:56.990964Z","shell.execute_reply":"2024-07-01T05:42:57.001924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.apply(make_pairs, axis=1)\ndisplay(df.head(2))\n\ntest_df = test_df.apply(make_pairs, axis=1)\ndisplay(test_df.head(2))","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:42:57.004172Z","iopub.execute_input":"2024-07-01T05:42:57.004618Z","iopub.status.idle":"2024-07-01T05:46:00.842076Z","shell.execute_reply.started":"2024-07-01T05:42:57.004586Z","shell.execute_reply":"2024-07-01T05:46:00.841150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Encoding Fail Statistics\n\nLet's examine how many samples have encoding issues. From the code below, we can see that only $1\\%$ of the samples failed to be encoded, while $99\\%$ of the samples don't have any issues. A similar pattern can be expected for the test data as well. Thus, considering empty strings for this small portion of the data will not have much impact on our training and inference.","metadata":{}},{"cell_type":"code","source":"df.encode_fail.value_counts(normalize=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:00.843269Z","iopub.execute_input":"2024-07-01T05:46:00.843559Z","iopub.status.idle":"2024-07-01T05:46:00.855046Z","shell.execute_reply.started":"2024-07-01T05:46:00.843533Z","shell.execute_reply":"2024-07-01T05:46:00.854120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"class DataFrameStatsProcessor:\n    def __init__(self, df):\n        self.df = df\n\n    def _is_empty(self, string: str) -> bool:\n        return bool(re.match(\"^\\s*$\", string))\n\n    def _len(self, string: str) -> int:\n        if string is None:\n            return 0\n        return len(string)\n\n    def _add_len_stats(self, col: str) -> pd.DataFrame:\n        if col == \"prompt\":\n            col_prefix = \"p_len\"\n        elif col == \"response_a\":\n            col_prefix = \"res_a_len\"\n        elif col == \"response_b\":\n            col_prefix = \"res_b_len\"\n        \n        self.df[f\"{col_prefix}_sum\"] = self.df[col].apply(lambda x: sum(self._len(s) for s in x))\n        self.df[f\"{col_prefix}_mean\"] =  self.df[col].apply(lambda x: np.mean(list(self._len(s) for s in x)))\n        self.df[f\"{col_prefix}_max\"] = self.df[col].apply(lambda x: max(self._len(s) for s in x))\n        self.df[f\"{col_prefix}_sum_log\"] = np.log1p(self.df[f\"{col_prefix}_sum\"])\n        self.df[f\"{col_prefix}_mean_log\"] =  np.log1p(self.df[f\"{col_prefix}_mean\"])\n        self.df[f\"{col_prefix}_max_log\"] = np.log1p(self.df[f\"{col_prefix}_max\"])\n        \n        return self.df\n    \n    def z_score_normalize(self, columns):\n        \"\"\"\n        对指定的列进行Z得分归一化。\n        参数:\n            columns (list): 需要进行Z得分归一化的列名列表。\n        \"\"\"\n        for col in columns:\n            self.df[col] = (self.df[col] - self.df[col].mean()) / self.df[col].std()\n    \n    def process_dataframe(self):\n        self.df[\"n_prompts\"] = self.df[\"prompt\"].apply(lambda x: len(x))\n        self.df[\"n_res_a\"] = self.df[\"response_a\"].apply(lambda x: len(x))\n        self.df[\"n_res_b\"] = self.df[\"response_b\"].apply(lambda x: len(x))\n        assert ((self.df[\"n_prompts\"] == self.df[\"n_res_a\"]) & (self.df[\"n_prompts\"] == self.df[\"n_res_b\"])).all()\n\n        self.df[\"n_na_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n        self.df[\"n_empty_prompts\"] = self.df[\"prompt\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n        self.df[\"n_na_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n        self.df[\"n_empty_res_a\"] = self.df[\"response_a\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n        self.df[\"n_na_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is None else 0 for p in ps))\n        self.df[\"n_empty_res_b\"] = self.df[\"response_b\"].apply(lambda ps: sum(1 if p is not None and self._is_empty(p) else 0 for p in ps))\n\n        self.df[\"n_miss_res_a\"] = self.df[\"n_na_res_a\"] + self.df[\"n_empty_res_a\"]\n        self.df[\"n_miss_res_b\"] = self.df[\"n_na_res_b\"] + self.df[\"n_empty_res_b\"]\n\n        self.df[\"n_eff_res_a\"] = self.df[\"n_res_a\"] - self.df[\"n_miss_res_a\"]\n        self.df[\"n_eff_res_b\"] = self.df[\"n_res_b\"] - self.df[\"n_miss_res_b\"]\n\n        self._add_len_stats(\"prompt\")\n        self._add_len_stats(\"response_a\")\n        self._add_len_stats(\"response_b\")\n\n        self.df[\"res_len_mean_diff\"] = self.df[\"res_a_len_mean\"] - self.df[\"res_b_len_mean\"]\n        self.df[\"res_len_mean_diff_clip\"] = self.df[\"res_len_mean_diff\"].clip(-6000, 6000)\n\n        self.df[\"n_miss_prompts\"] = self.df[\"n_na_prompts\"] + self.df[\"n_empty_prompts\"]\n        self.df[\"n_eff_prompts\"] = self.df[\"n_prompts\"] - self.df[\"n_miss_prompts\"]\n\n        self.df[\"na_prompt_ratio\"] = self.df[\"n_na_prompts\"] / self.df[\"n_prompts\"]\n        self.df[\"empty_prompt_ratio\"] = self.df[\"n_empty_prompts\"] / self.df[\"n_prompts\"]\n        self.df[\"miss_prompt_ratio\"] = self.df[\"n_miss_prompts\"] / self.df[\"n_prompts\"]\n\n        self.df[\"na_res_a_ratio\"] = self.df[\"n_na_res_a\"] / self.df[\"n_res_a\"]\n        self.df[\"empty_res_a_ratio\"] = self.df[\"n_empty_res_a\"] / self.df[\"n_res_a\"]\n        self.df[\"miss_res_a_ratio\"] = self.df[\"n_miss_res_a\"] / self.df[\"n_res_a\"]\n        self.df[\"na_res_b_ratio\"] = self.df[\"n_na_res_b\"] / self.df[\"n_res_b\"]\n        self.df[\"empty_res_b_ratio\"] = self.df[\"n_empty_res_b\"] / self.df[\"n_res_b\"]\n        self.df[\"miss_res_b_ratio\"] = self.df[\"n_miss_res_b\"] / self.df[\"n_res_b\"]\n\n        for col, col_prefix in zip([\"prompt\", \"response_a\", \"response_b\"], [\"p_len\", \"res_a_len\", \"res_b_len\"]):\n            self.df[f\"{col_prefix}_med\"] = self.df[col].apply(lambda x: np.median(list(self._len(s) for s in x)))\n            self.df[f\"{col_prefix}_std\"] = self.df[col].apply(lambda x: np.std(list(self._len(s) for s in x)))\n\n        self.df[\"p_len_eff_mean\"] = self.df[\"p_len_sum\"] / self.df[\"n_eff_prompts\"]\n        self.df[\"res_a_len_eff_mean\"] = self.df[\"res_a_len_sum\"] / self.df[\"n_eff_res_a\"]\n        self.df[\"res_b_len_eff_mean\"] = self.df[\"res_b_len_sum\"] / self.df[\"n_eff_res_b\"]\n\n        for stats in [\"sum\", \"mean\", \"max\", \"med\", \"eff_mean\"]:\n            self.df[f\"p_a_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_a_len_{stats}\"]\n            self.df[f\"p_b_{stats}_diff\"] = self.df[f\"p_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n            self.df[f\"a_b_{stats}_diff\"] = self.df[f\"res_a_len_{stats}\"] - self.df[f\"res_b_len_{stats}\"]\n            \n        len_feature_a_col = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n                     \"p_a_eff_mean_diff\"]\n        \n        len_feature_b_col = [\"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n                             \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n                             \"p_b_eff_mean_diff\"]\n        \n        numerical_feature_columns = [\"res_a_len_sum\",\"res_a_len_mean\",\"res_a_len_max\",\"res_a_len_sum_log\",\"res_a_len_mean_log\",\"res_a_len_max_log\",\n                                     \"res_a_len_med\",\"res_a_len_std\",\"res_a_len_eff_mean\",\"p_a_sum_diff\",\"p_a_mean_diff\",\"p_a_max_diff\",\"p_a_med_diff\",\n                                     \"p_a_eff_mean_diff\", \"res_b_len_sum\",\"res_b_len_mean\",\"res_b_len_max\",\"res_b_len_sum_log\",\"res_b_len_mean_log\",\"res_b_len_max_log\",\n                                     \"res_b_len_med\",\"res_b_len_std\",\"res_b_len_eff_mean\",\"p_b_sum_diff\",\"p_b_mean_diff\",\"p_b_max_diff\",\"p_b_med_diff\",\n                                     \"p_b_eff_mean_diff\"]\n        # 确保不除以零进行归一化\n        for col in numerical_feature_columns:\n            if self.df[col].std() == 0:\n                print(f\"Warning: Standard deviation is zero for column {col}. Skipping normalization.\")\n            else:\n                self.z_score_normalize([col])\n                \n        self.df = self.df.fillna(0)\n        \n        # 选择这些列并将它们转换为列表\n        len_features_a = self.df[len_feature_a_col].values.tolist()\n        len_features_b = self.df[len_feature_b_col].values.tolist()\n\n        return len_features_a, len_features_b","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:00.856673Z","iopub.execute_input":"2024-07-01T05:46:00.857073Z","iopub.status.idle":"2024-07-01T05:46:00.893205Z","shell.execute_reply.started":"2024-07-01T05:46:00.857040Z","shell.execute_reply":"2024-07-01T05:46:00.892273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Split\n\nIn the code snippet provided below, we will divide the existing data into training and validation using a stratification of `class_label` column.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split  # Import package\n\ntrain_df, valid_df = train_test_split(df, test_size=0.2, stratify=df[\"class_label\"])","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-01T05:46:00.894577Z","iopub.execute_input":"2024-07-01T05:46:00.895333Z","iopub.status.idle":"2024-07-01T05:46:01.457614Z","shell.execute_reply.started":"2024-07-01T05:46:00.895301Z","shell.execute_reply":"2024-07-01T05:46:01.456724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing\n\n**What it does:** The preprocessor takes input strings and transforms them into a dictionary (`token_ids`, `padding_mask`) containing preprocessed tensors. This process starts with tokenization, where input strings are converted into sequences of token IDs.\n\n**Why it's important:** Initially, raw text data is complex and challenging for modeling due to its high dimensionality. By converting text into a compact set of tokens, such as transforming `\"The quick brown fox\"` into `[\"the\", \"qu\", \"##ick\", \"br\", \"##own\", \"fox\"]`, we simplify the data. Many models rely on special tokens and additional tensors to understand input. These tokens help divide input and identify padding, among other tasks. Making all sequences the same length through padding boosts computational efficiency, making subsequent steps smoother.\n\nExplore the following pages to access the available preprocessing and tokenizer layers in **KerasNLP**:\n- [Preprocessing](https://keras.io/api/keras_nlp/preprocessing_layers/)\n- [Tokenizers](https://keras.io/api/keras_nlp/tokenizers/)","metadata":{}},{"cell_type":"code","source":"preprocessor = keras_nlp.models.DebertaV3Preprocessor.from_preset(\n    preset=CFG.preset, \n    sequence_length=CFG.sequence_length, \n)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:01.459033Z","iopub.execute_input":"2024-07-01T05:46:01.459337Z","iopub.status.idle":"2024-07-01T05:46:06.958895Z","shell.execute_reply.started":"2024-07-01T05:46:01.459300Z","shell.execute_reply":"2024-07-01T05:46:06.957936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We'll use the `preprocessing_fn` function to transform each text option using the `dataset.map(preprocessing_fn)` method.","metadata":{}},{"cell_type":"code","source":"def preprocess_fn(text, label=None, features_a=None, features_b=None):\n    text = preprocessor(text)\n    if features_a is not None:\n        text['features_a'] = features_a\n    if features_b is not None:\n         text['features_b'] = features_b\n    return (text, label) if label is not None else text  # Return processed text and label if available","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:06.960133Z","iopub.execute_input":"2024-07-01T05:46:06.960423Z","iopub.status.idle":"2024-07-01T05:46:06.965760Z","shell.execute_reply.started":"2024-07-01T05:46:06.960396Z","shell.execute_reply":"2024-07-01T05:46:06.964931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# FGM","metadata":{}},{"cell_type":"code","source":"# # 添加 FGM 扰动函数\n# def fgm_perturb(features, epsilon=1.0):\n#     # 计算扰动量，epsilon 为扰动比例\n#     perturbation = np.random.uniform(-1, 1, features.shape) * epsilon\n#     # 应用扰动\n#     return features + perturbation","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:06.967153Z","iopub.execute_input":"2024-07-01T05:46:06.967510Z","iopub.status.idle":"2024-07-01T05:46:06.978818Z","shell.execute_reply.started":"2024-07-01T05:46:06.967479Z","shell.execute_reply":"2024-07-01T05:46:06.978090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # 修改数据预处理函数以包含 FGM 扰动\n# def preprocess_fn(text, label=None, features_a=None, features_b=None, is_fgm=False, epsilon=1.0):\n#     # 预处理文本\n#     text = preprocessor(text)\n#     if features_a is not None:\n#         if is_fgm:\n#             # 如果是 FGM，应用扰动\n#             features_a = fgm_perturb(features_a, epsilon)\n#         text['features_a'] = features_a\n#     if features_b is not None:\n#         if is_fgm:\n#             # 如果是 FGM，应用扰动\n#             features_b = fgm_perturb(features_b, epsilon)\n#         text['features_b'] = features_b\n#     return (text, label) if label is not None else text","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:06.984351Z","iopub.execute_input":"2024-07-01T05:46:06.984817Z","iopub.status.idle":"2024-07-01T05:46:06.991620Z","shell.execute_reply.started":"2024-07-01T05:46:06.984791Z","shell.execute_reply":"2024-07-01T05:46:06.990902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AWP","metadata":{}},{"cell_type":"code","source":"#定义 AWP 扰动函数\ndef awp_perturb(model, epsilon=1e-4):\n    for layer in model.layers:\n        if hasattr(layer, 'kernel'):\n            # 获取权重\n            weights = layer.kernel\n            # 计算扰动\n            perturbation = tf.random.normal(weights.shape, stddev=epsilon)\n            # 应用扰动\n            layer.kernel.assign_add(perturbation)\n\n#创建 AWP 回调函数\nclass AWPCallback(keras.callbacks.Callback):\n    def __init__(self, epsilon):\n        super(AWPCallback, self).__init__()\n        self.epsilon = epsilon\n\n    def on_batch_begin(self, batch, logs=None):\n        # 在每个批次开始时应用 AWP 扰动\n        awp_perturb(self.model, self.epsilon)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:06.992834Z","iopub.execute_input":"2024-07-01T05:46:06.993228Z","iopub.status.idle":"2024-07-01T05:46:07.002199Z","shell.execute_reply.started":"2024-07-01T05:46:06.993197Z","shell.execute_reply":"2024-07-01T05:46:07.001366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 🍚 | DataLoader\n\nThe code below sets up a robust data flow pipeline using `tf.data.Dataset` for data processing. Notable aspects of `tf.data` include its ability to simplify pipeline construction and represent components in sequences.\n\nTo learn more about `tf.data`, refer to this [documentation](https://www.tensorflow.org/guide/data).","metadata":{}},{"cell_type":"code","source":"def build_dataset_with_features(texts, labels=None, features_a=None, features_b=None, batch_size=32, is_fgm=False,  epsilon=1.0,\n                                cache=True, shuffle=1024):\n    AUTO = tf.data.AUTOTUNE\n    if (features_a is not None) and (features_b is not None):\n        slices = (texts, None, features_a, features_b) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3), features_a, features_b)  # Create slices\n    else:\n        slices = (texts,) if labels is None else (texts, keras.utils.to_categorical(labels, num_classes=3))  # Create slices\n    ds = tf.data.Dataset.from_tensor_slices(slices)\n    ds = ds.cache() if cache else ds\n    ds = ds.map(preprocess_fn, num_parallel_calls=AUTO)\n#     ds = ds.map(lambda x: preprocess_fn(x, features_a=features_a, features_b=features_b, is_fgm=is_fgm, epsilon=epsilon),\n#                 num_parallel_calls=tf.data.AUTOTUNE)\n    opt = tf.data.Options()\n    if shuffle:\n        ds = ds.shuffle(shuffle, seed=CFG.seed)\n        opt.experimental_deterministic = False\n    ds = ds.with_options(opt)\n    ds = ds.batch(batch_size, drop_remainder=False)\n    ds = ds.prefetch(AUTO)\n    \n    return ds","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-01T05:46:07.003226Z","iopub.execute_input":"2024-07-01T05:46:07.003498Z","iopub.status.idle":"2024-07-01T05:46:07.013033Z","shell.execute_reply.started":"2024-07-01T05:46:07.003475Z","shell.execute_reply":"2024-07-01T05:46:07.012260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Train/Valid Dataloader","metadata":{}},{"cell_type":"code","source":"train_features_processor = DataFrameStatsProcessor(train_df.copy())\ntrain_features_a, train_features_b = train_features_processor.process_dataframe()\nvalid_features_processor = DataFrameStatsProcessor(valid_df.copy())\nvalid_features_a, valid_features_b = valid_features_processor.process_dataframe()","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:07.014293Z","iopub.execute_input":"2024-07-01T05:46:07.014974Z","iopub.status.idle":"2024-07-01T05:46:37.861252Z","shell.execute_reply.started":"2024-07-01T05:46:07.014935Z","shell.execute_reply":"2024-07-01T05:46:37.860438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Train\ntrain_texts = train_df.options.tolist()  \ntrain_labels = train_df.class_label.tolist() \ntrain_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b, \n                         batch_size=CFG.batch_size,\n                         shuffle=True)\n# # Valid\nvalid_texts = valid_df.options.tolist()  \nvalid_labels = valid_df.class_label.tolist() \nvalid_ds = build_dataset_with_features(valid_texts, valid_labels, valid_features_a, valid_features_b, \n                         batch_size=CFG.batch_size,\n                         shuffle=False)\nprint(train_ds)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-07-01T05:46:37.862426Z","iopub.execute_input":"2024-07-01T05:46:37.862761Z","iopub.status.idle":"2024-07-01T05:46:58.426303Z","shell.execute_reply.started":"2024-07-01T05:46:37.862728Z","shell.execute_reply":"2024-07-01T05:46:58.425400Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LR Schedule\n\nImplementing a learning rate scheduler is crucial for transfer learning. The learning rate initiates at `lr_start` and gradually tapers down to `lr_min` using various techniques, including:\n- `step`: Lowering the learning rate in step-wise manner resembling stairs.\n- `cos`: Utilizing a cosine curve to gradually reduce the learning rate.\n- `exp`: Exponentially decreasing the learning rate.\n\n**Importance:** A well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation.","metadata":{}},{"cell_type":"code","source":"import math\n\ndef get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n    lr_start, lr_max, lr_min = 1.0e-6, 0.6e-6 * batch_size, 1e-6\n    lr_ramp_ep, lr_sus_ep, lr_decay = 2, 0, 0.8\n\n    def lrfn(epoch):  # Learning rate update function\n        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n        elif mode == 'cos':\n            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n            phase = math.pi * decay_epoch_index / decay_total_epochs\n            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n        return lr\n\n    if plot:  # Plot lr curve if plot is True\n        plt.figure(figsize=(10, 5))\n        plt.plot(np.arange(epochs), [lrfn(epoch) for epoch in np.arange(epochs)], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('lr')\n        plt.title('LR Scheduler')\n        plt.show()\n\n    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-01T05:46:58.427518Z","iopub.execute_input":"2024-07-01T05:46:58.427821Z","iopub.status.idle":"2024-07-01T05:46:58.438250Z","shell.execute_reply.started":"2024-07-01T05:46:58.427795Z","shell.execute_reply":"2024-07-01T05:46:58.437393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_cb = get_lr_callback(CFG.batch_size, epochs=CFG.epochs, plot=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:58.439264Z","iopub.execute_input":"2024-07-01T05:46:58.439518Z","iopub.status.idle":"2024-07-01T05:46:58.730319Z","shell.execute_reply.started":"2024-07-01T05:46:58.439496Z","shell.execute_reply":"2024-07-01T05:46:58.729401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Checkpointing\n\nThe following code will create a callback that will save the best checkpoint of the model during training, which we will use for inference in the submission.","metadata":{}},{"cell_type":"code","source":"ckpt_cb = keras.callbacks.ModelCheckpoint(f'best_model.weights.h5',\n                                          monitor='val_log_loss',\n                                          save_best_only=True,\n                                          save_weights_only=True,\n                                          mode='min')  # Get Model checkpoint callback","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-01T05:46:58.731607Z","iopub.execute_input":"2024-07-01T05:46:58.731929Z","iopub.status.idle":"2024-07-01T05:46:58.738164Z","shell.execute_reply.started":"2024-07-01T05:46:58.731894Z","shell.execute_reply":"2024-07-01T05:46:58.737257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Metric\n\nThe metric for this competition is **Log Loss**. This metric can be expressed mathematically as,\n\n$$\n\\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} \\left( y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i) \\right)\n$$\n\nwhere $ N $ is the number of samples, $ y_i $ is the true label, and $ p_i $ is the predicted probability of the sample belonging to the positive class.\n\nNote that this metric is similar to categorical cross entropy widely used in classification tasks. Thus, we don't need to implement the loss from scratch. As the Keras library already has an implementation of this metric, we will simply use the metric to monitor performance of our model.\n","metadata":{}},{"cell_type":"code","source":"log_loss = keras.metrics.CategoricalCrossentropy(name=\"log_loss\", label_smoothing=0.1, from_logits=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:58.739147Z","iopub.execute_input":"2024-07-01T05:46:58.739411Z","iopub.status.idle":"2024-07-01T05:46:58.760424Z","shell.execute_reply.started":"2024-07-01T05:46:58.739387Z","shell.execute_reply":"2024-07-01T05:46:58.759532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras import regularizers\nfrom tensorflow.keras.layers import Dropout\n\nwith strategy.scope():\n\n    # 将所有输入层整合到一个字典中\n    inputs = {\n        \"token_ids\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"token_ids\"),\n        \"padding_mask\": keras.layers.Input(shape=(2, None), dtype=tf.int32, name=\"padding_mask\"),\n        \"features_a\": keras.layers.Input(shape=(14,), name=\"features_a\", dtype=tf.float32),\n        \"features_b\": keras.layers.Input(shape=(14,), name=\"features_b\", dtype=tf.float32),\n    }\n    \n    # Create a DebertaV3Classifier backbone\n    backbone = keras_nlp.models.DebertaV3Backbone.from_preset(\n        CFG.preset,\n    )\n\n   # 修改 response_a 和 response_b 的创建方式，包含 padding_mask\n    response_a = {\n        \"token_ids\": inputs[\"token_ids\"][:, 0, :],\n        \"padding_mask\": inputs[\"padding_mask\"][:, 0, :]\n    }\n    embed_a = backbone(response_a)\n\n    response_b = {\n        \"token_ids\": inputs[\"token_ids\"][:, 1, :],\n        \"padding_mask\": inputs[\"padding_mask\"][:, 1, :]\n    }\n    embed_b = backbone(response_b)\n    \n    # 将数值特征嵌入\n    len_features_a_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_a\"])\n    len_features_b_embedding = keras.layers.Dense(512, activation='relu')(inputs[\"features_b\"])\n    \n    # 使用 Flatten 层将数值特征嵌入展平为二维张量\n    flattened_len_features_a = keras.layers.Flatten()(len_features_a_embedding)\n    flattened_len_features_b = keras.layers.Flatten()(len_features_b_embedding)\n    \n    embed_a = keras.layers.GlobalAveragePooling1D()(embed_a)\n    embed_b = keras.layers.GlobalAveragePooling1D()(embed_b)\n    embeds_text_features_a = keras.layers.Concatenate(axis=-1)([embed_a, flattened_len_features_a])\n    embeds_text_features_b = keras.layers.Concatenate(axis=-1)([embed_b, flattened_len_features_b])\n    \n    # 合并文本嵌入和数值特征嵌入\n    combined_embeds = keras.layers.Concatenate(axis=-1)([embeds_text_features_a, embeds_text_features_a])\n    \n    # 添加L2正则化和Dropout到模型中\n    combined_embeds = keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(1e-5))(combined_embeds)  # L2正则化\n    combined_embeds = Dropout(0.5)(combined_embeds)  # Dropout层，丢弃50%的神经元\n    \n    # 定义 temperature_scale 函数\n    def temperature_scale(logits, T=1.0):\n        return logits / T\n    \n    # 定义温度参数 T\n    T = 0.85\n    # 应用温度缩放\n    scaled_logits = temperature_scale(combined_embeds, T)\n    outputs = keras.layers.Dense(3, activation=\"softmax\", name=\"classifier\")(scaled_logits)\n    \n    model = keras.Model(inputs,  outputs)\n    \n    # Compile the model with optimizer, loss, and metrics\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=1e-6, clipnorm=1.0),\n        loss=keras.losses.CategoricalCrossentropy(label_smoothing=0.1, from_logits=False),\n        metrics=[\n            log_loss,\n            keras.metrics.CategoricalAccuracy(name=\"accuracy\"),\n        ],\n    )\n    \n    # 添加 AWP 回调到模型训练中\n    awp_cb = AWPCallback(epsilon=1e-4)  # 您可以根据需要调整 epsilon 的值","metadata":{"execution":{"iopub.status.busy":"2024-07-01T05:46:58.762014Z","iopub.execute_input":"2024-07-01T05:46:58.762587Z","iopub.status.idle":"2024-07-01T05:47:06.187392Z","shell.execute_reply.started":"2024-07-01T05:46:58.762554Z","shell.execute_reply":"2024-07-01T05:47:06.186599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Summary","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-01T05:47:06.188476Z","iopub.execute_input":"2024-07-01T05:47:06.188774Z","iopub.status.idle":"2024-07-01T05:47:06.233585Z","shell.execute_reply.started":"2024-07-01T05:47:06.188747Z","shell.execute_reply":"2024-07-01T05:47:06.232747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# try:\n#     history = model.fit(\n#         train_ds,\n#         epochs=CFG.epochs,\n#         validation_data=valid_ds,\n#         callbacks=[lr_cb, ckpt_cb]\n#     )\n# except tf.errors.InvalidArgumentError as e:\n#     print(f\"出现无效参数错误：{e}\")\ntry:\n    history = model.fit(\n        train_ds,\n        epochs=CFG.epochs,\n        validation_data=valid_ds,\n        callbacks=[lr_cb, ckpt_cb, awp_cb]  # 将 AWP 回调添加到训练回调列表中\n    )\nexcept tf.errors.InvalidArgumentError as e:\n    print(f\"出现无效参数错误：{e}\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-07-01T05:47:06.234698Z","iopub.execute_input":"2024-07-01T05:47:06.234990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Best Model\n\nAfter training, let's load the weight with best result to get the best performance.","metadata":{}},{"cell_type":"code","source":"model.load_weights('/kaggle/working/best_model.weights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"# # 使用 FGM 扰动的数据集评估模型\n# fgm_ds = build_dataset_with_features(train_texts, train_labels, train_features_a, train_features_b,\n#                                      is_fgm=True, epsilon=1.0)\n# evaluation_results = model.evaluate(fgm_ds)\n\n# print(f\"Evaluation results on FGM perturbed dataset: {evaluation_results}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_features_processor = DataFrameStatsProcessor(test_df)\ntest_df_features_a, test_df_features_b = test_df_features_processor.process_dataframe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_texts = test_df.options.tolist()\ntest_ds = build_dataset_with_features(test_texts, features_a=test_df_features_a, features_b=test_df_features_b,\n                         batch_size=min(len(test_df), CFG.batch_size),\n                         shuffle=False)\nprint(test_ds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = model.predict(test_ds, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission\n\nFollowing code will prepare the submission file.","metadata":{}},{"cell_type":"code","source":"sub_df = test_df[[\"id\"]].copy()\nsub_df[CFG.class_names] = test_preds.tolist()\nsub_df.to_csv(\"submission.csv\", index=False)\nsub_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}